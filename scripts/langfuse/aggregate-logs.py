#!/usr/bin/env python3
"""
LangFuse Log Aggregator

Claude Code ë° Cascade ë¡œê·¸ë¥¼ LangFuse Trace/Observation í˜•ì‹ìœ¼ë¡œ ë³€í™˜

Usage:
    python3 aggregate-logs.py --anonymize --output langfuse-data.json
"""

import json
import hashlib
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional

class LangFuseAggregator:
    """Claude Code ë° Cascade ë¡œê·¸ë¥¼ LangFuse í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""

    def __init__(self, anonymize: bool = False):
        self.anonymize = anonymize
        self.traces: Dict[str, Dict] = {}
        self.observations: List[Dict] = []
        self.session_traces: Dict[str, str] = {}  # timestamp â†’ trace_id ë§¤í•‘

    def load_claude_logs(self, log_path: str) -> None:
        """Claude Code ë¡œê·¸ ë¡œë“œ ë° ë³€í™˜"""
        if not Path(log_path).exists():
            print(f"âš ï¸  Claude logs not found: {log_path}")
            return

        with open(log_path, 'r') as f:
            for line in f:
                try:
                    event = json.loads(line.strip())
                    self._process_claude_event(event)
                except json.JSONDecodeError:
                    continue

    def load_cascade_logs(self, log_path: str) -> None:
        """Cascade ë¡œê·¸ ë¡œë“œ ë° ë³€í™˜"""
        if not Path(log_path).exists():
            print(f"âš ï¸  Cascade logs not found: {log_path}")
            return

        with open(log_path, 'r') as f:
            for line in f:
                try:
                    event = json.loads(line.strip())
                    self._process_cascade_event(event)
                except json.JSONDecodeError:
                    continue

    def _normalize_timestamp(self, timestamp: str) -> str:
        """Timestampë¥¼ LangFuse í˜¸í™˜ ISO 8601 UTC í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            # ì´ë¯¸ Zë‚˜ íƒ€ì„ì¡´ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if timestamp.endswith('Z') or '+' in timestamp or timestamp.count(':') > 2:
                return timestamp

            # íƒ€ì„ì¡´ ì •ë³´ ì—†ìœ¼ë©´ Z ì¶”ê°€ (UTC)
            return f"{timestamp}Z"
        except:
            # ì‹¤íŒ¨ ì‹œ í˜„ì¬ ì‹œê°„ (UTC)
            return datetime.utcnow().isoformat() + 'Z'

    def _process_claude_event(self, event: Dict) -> None:
        """Claude Code ì´ë²¤íŠ¸ â†’ LangFuse Observation"""
        event_type = event.get('event')
        timestamp = self._normalize_timestamp(event.get('timestamp', datetime.utcnow().isoformat()))

        if event_type == 'session_start':
            # ìƒˆ Trace ìƒì„±
            trace_id = event.get('session_id', self._generate_trace_id(event))
            self.traces[trace_id] = {
                'id': trace_id,
                'name': f"Claude Session",
                'timestamp': timestamp,
                'tags': self._extract_tags(event),
                'metadata': {
                    'project': self._anonymize_string(event.get('project', 'unknown')),
                    'user': self._anonymize_string(event.get('user', 'unknown')),
                    'tool': 'claude-code'
                }
            }
            # íƒ€ì„ìŠ¤íƒ¬í”„ â†’ trace_id ë§¤í•‘ ì €ì¥
            self.session_traces[timestamp] = trace_id

        elif event_type in ['keyword_analysis', 'cache_injection', 'validation_complete']:
            # Observation ìƒì„±
            trace_id = event.get('session_id') or self._find_trace_by_time(timestamp)
            if not trace_id:
                return

            self.observations.append({
                'traceId': trace_id,
                'name': self._format_event_name(event_type, event),
                'type': 'SPAN',
                'startTime': timestamp,
                'endTime': timestamp,
                'level': self._get_level(event),
                'metadata': self._extract_metadata(event),
                'tags': self._extract_tags(event)
            })

    def _process_cascade_event(self, event: Dict) -> None:
        """Cascade ì´ë²¤íŠ¸ â†’ LangFuse Observation"""
        timestamp = self._normalize_timestamp(event.get('timestamp', datetime.utcnow().isoformat()))
        task_name = event.get('task', 'unknown')
        status_code = event.get('status', 1)
        duration = event.get('duration', 0)

        # ê°€ì¥ ê°€ê¹Œìš´ Claude ì„¸ì…˜ ì°¾ê¸°
        trace_id = self._find_trace_by_time(timestamp)
        if not trace_id:
            # Cascade ì „ìš© Trace ìƒì„±
            trace_id = f"cascade-{timestamp}"
            self.traces[trace_id] = {
                'id': trace_id,
                'name': 'Cascade Session',
                'timestamp': timestamp,
                'tags': ['cascade'],
                'metadata': {'tool': 'cascade'}
            }

        # ì‹œì‘ ì‹œê°„ ê³„ì‚°
        start_time = self._calculate_start_time(timestamp, duration)

        self.observations.append({
            'traceId': trace_id,
            'name': f"Cascade: {task_name}",
            'type': 'SPAN',
            'startTime': start_time,
            'endTime': timestamp,
            'level': 'DEFAULT' if status_code == 0 else 'ERROR',
            'statusMessage': f"Exit code: {status_code}",
            'metadata': {
                'task': task_name,
                'duration_seconds': duration,
                'exit_code': status_code
            },
            'tags': ['cascade', task_name]
        })

    def _anonymize_string(self, value: str) -> str:
        """ë¬¸ìì—´ ìµëª…í™”"""
        if not self.anonymize or not value:
            return value

        # íŒŒì¼ëª… ìµëª…í™”
        if value.endswith(('.java', '.kt', '.py')):
            return '*.java'

        # ì‚¬ìš©ìëª… ìµëª…í™” (ì´ë©”ì¼ ì œì™¸)
        if '@' not in value:
            hashed = hashlib.sha256(value.encode()).hexdigest()[:8]
            return f"user-{hashed}"

        return value

    def _extract_tags(self, event: Dict) -> List[str]:
        """ì´ë²¤íŠ¸ì—ì„œ íƒœê·¸ ì¶”ì¶œ"""
        tags = []

        if 'layer' in event:
            tags.append(event['layer'])
        if 'environment' in event:
            tags.append(event['environment'])

        return tags

    def _extract_metadata(self, event: Dict) -> Dict:
        """ì´ë²¤íŠ¸ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {}

        # ìµëª…í™”ê°€ í•„ìš”í•œ í•„ë“œ
        if 'file' in event:
            metadata['file'] = self._anonymize_string(event['file'])

        # ìˆ«ì/í†µê³„ í•„ë“œ (ìµëª…í™” ë¶ˆí•„ìš”)
        for key in ['context_score', 'rules_loaded', 'estimated_tokens',
                    'validation_time_ms', 'total_rules']:
            if key in event:
                metadata[key] = event[key]

        return metadata

    def _get_level(self, event: Dict) -> str:
        """ì´ë²¤íŠ¸ ë ˆë²¨ ê²°ì •"""
        if event.get('status') == 'failed':
            return 'ERROR'
        elif event.get('status') == 'warning':
            return 'WARNING'
        return 'DEFAULT'

    def _format_event_name(self, event_type: str, event: Dict) -> str:
        """ì´ë²¤íŠ¸ ì´ë¦„ í¬ë§·íŒ…"""
        if event_type == 'keyword_analysis':
            return "Keyword Analysis"
        elif event_type == 'cache_injection':
            layer = event.get('layer', 'unknown')
            return f"Cache Injection: {layer}"
        elif event_type == 'validation_complete':
            return "Code Validation"
        return event_type

    def _find_trace_by_time(self, timestamp: str) -> Optional[str]:
        """íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ê°€ì¥ ê°€ê¹Œìš´ Trace ì°¾ê¸°"""
        if not self.session_traces:
            return None

        # ê°„ë‹¨í•œ êµ¬í˜„: ê°€ì¥ ìµœê·¼ trace ë°˜í™˜
        return list(self.traces.keys())[-1] if self.traces else None

    def _calculate_start_time(self, end_time: str, duration: float) -> str:
        """ì‹œì‘ ì‹œê°„ ê³„ì‚°"""
        try:
            end = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
            start = end - timedelta(seconds=duration)
            return start.isoformat()
        except:
            return end_time

    def _generate_trace_id(self, event: Dict) -> str:
        """Trace ID ìƒì„±"""
        timestamp = event.get('timestamp', datetime.utcnow().isoformat())
        return f"session-{timestamp}"

    def export_to_langfuse(self) -> Dict:
        """LangFuse API í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        return {
            'traces': list(self.traces.values()),
            'observations': self.observations
        }

def main():
    parser = argparse.ArgumentParser(
        description='Aggregate Claude Code and Cascade logs for LangFuse'
    )
    parser.add_argument(
        '--claude-logs',
        default='.claude/hooks/logs/hook-execution.jsonl',
        help='Path to Claude Code logs'
    )
    parser.add_argument(
        '--cascade-logs',
        default='.cascade/metrics.jsonl',
        help='Path to Cascade logs'
    )
    parser.add_argument(
        '--output',
        default='langfuse-data.json',
        help='Output file path'
    )
    parser.add_argument(
        '--anonymize',
        action='store_true',
        help='Anonymize sensitive data (usernames, filenames, etc.)'
    )
    parser.add_argument(
        '--telemetry',
        action='store_true',
        help='Enable telemetry mode (auto-read .langfuse.telemetry config)'
    )

    args = parser.parse_args()

    # í…”ë ˆë©”íŠ¸ë¦¬ ëª¨ë“œ: .langfuse.telemetry íŒŒì¼ í™•ì¸
    if args.telemetry:
        telemetry_file = Path('.langfuse.telemetry')
        if not telemetry_file.exists():
            print("âš ï¸  Telemetry mode enabled but .langfuse.telemetry not found")
            print("   Telemetry is disabled. Continuing with normal operation.")
            return

        # í…”ë ˆë©”íŠ¸ë¦¬ ì„¤ì • ì½ê¸°
        telemetry_config = {}
        with open(telemetry_file, 'r') as f:
            for line in f:
                if '=' in line:
                    key, value = line.strip().split('=', 1)
                    telemetry_config[key] = value

        # í…”ë ˆë©”íŠ¸ë¦¬ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ì¢…ë£Œ
        if telemetry_config.get('enabled', 'false').lower() != 'true':
            print("âš ï¸  Telemetry is disabled in .langfuse.telemetry")
            print("   Skipping telemetry upload.")
            return

        # ìµëª…í™” ê°•ì œ
        args.anonymize = True
        print("ğŸ”’ Telemetry mode: Anonymization enforced")

    print("ğŸš€ LangFuse Log Aggregator")
    print(f"   Claude logs: {args.claude_logs}")
    print(f"   Cascade logs: {args.cascade_logs}")
    print(f"   Anonymize: {args.anonymize}")

    aggregator = LangFuseAggregator(anonymize=args.anonymize)

    # ë¡œê·¸ ë¡œë“œ
    aggregator.load_claude_logs(args.claude_logs)
    aggregator.load_cascade_logs(args.cascade_logs)

    # LangFuse í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
    data = aggregator.export_to_langfuse()

    with open(args.output, 'w') as f:
        json.dump(data, f, indent=2)

    print(f"\nâœ… Export complete!")
    print(f"   Output: {args.output}")
    print(f"   Traces: {len(data['traces'])}")
    print(f"   Observations: {len(data['observations'])}")

if __name__ == '__main__':
    main()
