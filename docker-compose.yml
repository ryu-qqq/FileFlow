# ================================================================
# Fileflow Docker Compose Configuration (Local Development)
# ================================================================
# 목적: Bootstrap 모듈들을 Docker로 실행하되,
#       호스트 머신의 MySQL(3306)과 Redis(6379)에 연결
#
# Services:
#   - fileflow-web-api: REST API server (port 8083)
#   - fileflow-scheduler-pipeline: Pipeline processing (thumbnails + metadata)
#   - fileflow-scheduler-download: External URL downloads
#
# Prerequisites:
#   - 호스트 머신에 MySQL 3306 포트로 실행 중
#   - 호스트 머신에 Redis 6379 포트로 실행 중
#   - fileflow 데이터베이스 및 fileflow 사용자 생성 완료
#
# 사용법:
#   docker-compose up -d              # 전체 실행
#   docker-compose up web-api         # 특정 서비스만 실행
#   docker-compose logs -f web-api    # 로그 확인
#   docker-compose down               # 중지 및 제거
# ================================================================

version: '3.8'

services:

  # ================================================================
  # Fileflow Web API (REST API Server)
  # ================================================================
  fileflow-web-api:
    build:
      context: bootstrap/bootstrap-web-api
      dockerfile: Dockerfile.simple
    container_name: fileflow-web-api
    environment:
      SPRING_PROFILES_ACTIVE: local
      # MySQL 연결 (호스트 머신의 MySQL 3306 포트)
      SPRING_DATASOURCE_URL: jdbc:mysql://host.docker.internal:3306/fileflow?useUnicode=true&characterEncoding=utf8&serverTimezone=UTC
      SPRING_DATASOURCE_USERNAME: fileflow
      SPRING_DATASOURCE_PASSWORD: fileflow
      # Redis 연결 (호스트 머신의 Redis 6379 포트)
      SPRING_DATA_REDIS_HOST: host.docker.internal
      SPRING_DATA_REDIS_PORT: 6739
      SERVER_PORT: 8083
      # JVM Options
      JAVA_OPTS: >-
        -Xms512m
        -Xmx1024m
        -XX:+UseG1GC
        -XX:MaxGCPauseMillis=200
        -Dfile.encoding=UTF-8
        -Duser.timezone=Asia/Seoul
      # AWS S3 Configuration (환경 변수로 주입 필요)
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-your_access_key}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-your_secret_key}
      AWS_REGION: ${AWS_REGION:-ap-northeast-2}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME:-fileflow-bucket}
    ports:
      - "8083:8083"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - fileflow-network
    restart: unless-stopped

  # ================================================================
  # Fileflow Scheduler Pipeline (Thumbnail + Metadata Processing)
  # ================================================================
  fileflow-scheduler-pipeline:
    build:
      context: bootstrap/bootstrap-scheduler-pipeline
      dockerfile: Dockerfile.simple
    container_name: fileflow-scheduler-pipeline
    environment:
      SPRING_PROFILES_ACTIVE: local
      # MySQL 연결 (호스트 머신의 MySQL 3306 포트)
      SPRING_DATASOURCE_URL: jdbc:mysql://host.docker.internal:3306/fileflow?useUnicode=true&characterEncoding=utf8&serverTimezone=UTC
      SPRING_DATASOURCE_USERNAME: fileflow
      SPRING_DATASOURCE_PASSWORD: fileflow
      # Redis 연결 (호스트 머신의 Redis 6379 포트)
      SPRING_DATA_REDIS_HOST: host.docker.internal
      SPRING_DATA_REDIS_PORT: 6739
      # JVM Options
      JAVA_OPTS: >-
        -Xms256m
        -Xmx512m
        -XX:+UseG1GC
        -XX:MaxGCPauseMillis=200
        -Dfile.encoding=UTF-8
        -Duser.timezone=Asia/Seoul
      # AWS S3 Configuration
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-your_access_key}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-your_secret_key}
      AWS_REGION: ${AWS_REGION:-ap-northeast-2}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME:-fileflow-bucket}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - fileflow-network
    restart: unless-stopped

  # ================================================================
  # Fileflow Scheduler Download (External URL Downloads)
  # ================================================================
  fileflow-scheduler-download:
    build:
      context: bootstrap/bootstrap-scheduler-download
      dockerfile: Dockerfile.simple
    container_name: fileflow-scheduler-download
    environment:
      SPRING_PROFILES_ACTIVE: local
      # MySQL 연결 (호스트 머신의 MySQL 3306 포트)
      SPRING_DATASOURCE_URL: jdbc:mysql://host.docker.internal:3306/fileflow?useUnicode=true&characterEncoding=utf8&serverTimezone=UTC
      SPRING_DATASOURCE_USERNAME: fileflow
      SPRING_DATASOURCE_PASSWORD: fileflow
      # Redis 연결 (호스트 머신의 Redis 6379 포트)
      SPRING_DATA_REDIS_HOST: host.docker.internal
      SPRING_DATA_REDIS_PORT: 6739
      # JVM Options
      JAVA_OPTS: >-
        -Xms256m
        -Xmx512m
        -XX:+UseG1GC
        -XX:MaxGCPauseMillis=200
        -Dfile.encoding=UTF-8
        -Duser.timezone=Asia/Seoul
      # AWS S3 Configuration
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-your_access_key}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-your_secret_key}
      AWS_REGION: ${AWS_REGION:-ap-northeast-2}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME:-fileflow-bucket}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - fileflow-network
    restart: unless-stopped

# ========================================
# Networks
# ========================================
networks:
  fileflow-network:
    driver: bridge

# ========================================
# 참고사항
# ========================================
# 1. host.docker.internal:
#    - macOS/Windows: Docker Desktop에서 기본 지원
#    - Linux: docker run 시 --add-host=host.docker.internal:host-gateway 옵션 필요
#      또는 docker-compose.yml에서:
#      extra_hosts:
#        - "host.docker.internal:host-gateway"
#
# 2. 사전 준비 사항:
#    - 호스트 MySQL 3306 포트 실행 확인: mysql -h 127.0.0.1 -P 3306 -u fileflow -p
#    - 호스트 Redis 6739 포트 실행 확인: redis-cli -p 6739 ping
#    - fileflow 데이터베이스 생성 확인
#
# 3. 빌드 및 실행:
#    # JAR 파일 빌드
#    ./gradlew :bootstrap:bootstrap-web-api:bootJar
#    ./gradlew :bootstrap:bootstrap-scheduler-pipeline:bootJar
#    ./gradlew :bootstrap:bootstrap-scheduler-download:bootJar
#
#    # Docker 이미지 빌드
#    docker-compose build
#
#    # 실행
#    docker-compose up -d
#
#    # 로그 확인
#    docker-compose logs -f fileflow-web-api
#
# 4. ECS 배포 시 변경 사항:
#    - host.docker.internal → RDS 엔드포인트
#    - host.docker.internal → ElastiCache 엔드포인트
#    - 각 서비스를 별도의 ECS Task Definition으로 분리
#    - Task Definition마다 독립적인 CPU/메모리 할당
#
# 5. 환경 변수 우선순위:
#    Docker Compose environment > application-{profile}.yml > application.yml
